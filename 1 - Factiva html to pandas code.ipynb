{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 **Factiva Article Dataset Construction**\n",
    "\n",
    "#### 1.1 **Purpose:** This code takes html-formatted articles from Factiva search results and iteratively converts the html to pandas dataframes and then appends each dataframe of articles (df2) to a mother dataframe (df). It also shows post-hoc clean up of df, such as removing duplicate articles and oddly formatted quotation marks. The finished df is then fed into a different Python project that extracts and attributes quotes and paraphrases from decisions makers within these articles. \n",
    "\n",
    "##### NOTE: Factiva does not let you scrape their website. It also only lets you download a report of 100 articles at a time so I had to carefully go through each firm-year with over 100 articles and break up search date ranges to get as close to 100 as possible. \n",
    "\n",
    "#### 1.2 **Input data:** Create Factiva search queries manually, downloading each search result in RTF format. As part of this manual process I would recommend running a Python code to move the downloaded file and rename it to a folder of choice. I did this with two everything (screens, Factiva, tracking, renaming Python code, etc.) to speed up the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0: Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tkinter import *\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import timeit\n",
    "import striprtf\n",
    "import PyRTF\n",
    "import glob\n",
    "import re\n",
    "import sqlite3\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Run code on htmls\n",
    "\n",
    "#### This code converts the html file into a pandas dataset with each article creating one row. While the specific results below are from articles with specific reference to middle manager titles, the same code was used on the initial round of Factiva querries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder you'd like to use:\n",
    "path = r'C:/Users/danwilde/Dropbox (Penn)/Project - Fusion Industry/htmls/*'\n",
    "\n",
    "fields = ['AN', 'SE', 'HD', 'CR', 'WC', 'PD', 'ET', 'SN', 'SC', 'ED', 'PG', 'LA', 'CY', 'LP', 'TD', 'CT', 'RF', 'CO',\n",
    "          'IN', 'NS', 'RE', 'IPC', 'IPD', 'PUB']\n",
    "\n",
    "df = pd.DataFrame(columns=fields)\n",
    "\n",
    "t0 = time.time()\n",
    "n = 0\n",
    "for f in glob.glob(path + \"*.html\"):\n",
    "    t1 = time.time()\n",
    "    name = f.split('\\\\')\n",
    "    name = name[1]\n",
    "    file_div = name.split('_')\n",
    "    firm = file_div[0]\n",
    "    vertexid = file_div[1]\n",
    "    s = file_div[2]\n",
    "    e = file_div[3].split('.')[0]\n",
    "\n",
    "    df1 = pd.read_html(f, index_col=0)\n",
    "    df2 = pd.concat([l for l in df1 if 'HD' in l.index.values], axis=1).T\n",
    "    df2['Firm'] = firm\n",
    "    df2['vertex.id'] = vertexid\n",
    "    df2['start'] = s\n",
    "    df2['end'] = e\n",
    "    df = df.append(df2, ignore_index=True)\n",
    "    n += 1\n",
    "    t2 = time.time()\n",
    "    total = t1 - t0\n",
    "    print(n, firm, vertexid, s, e, \"time run:\", round(t2-t1,2), \"total hours:\", round((t2-t0)/(60*60),2), \"mean rate:\", round((t2-t0)/n,2))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 **Review**\n",
    "### These is the df of all articles from the middle manager Factiva search querries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
